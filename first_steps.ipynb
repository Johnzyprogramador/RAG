{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce0332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Okay, let\\'s break down quantum computing in a way that\\'s (hopefully!) understandable without getting bogged down in complex math. Here\\'s the core idea, broken down into simpler parts:\\n\\n**1. Classical Computers: Like Light Switches**\\n\\n* **How they work:** Traditional computers, like the one you\\'re using now, store information as **bits**. A bit is like a light switch â€“ it can be either ON (1) or OFF (0).  Everything a computer does â€“ from playing games to running software â€“ is ultimately based on manipulating these bits.\\n\\n**2. Quantum Computers: Like a Dimmer Switch and a Rainbow**\\n\\n* **How they work:** Quantum computers use **qubits**. This is where it gets interesting. Qubits aren\\'t just 0 or 1. They can be *both* 0 and 1 *at the same time*. This \"both at the same time\" state is called **superposition**. Think of it like a dimmer switch â€“ it can be anywhere between fully on and fully off, and even a little bit of both.\\n\\n* **Key Quantum Concepts:**\\n    * **Superposition:** As mentioned, a qubit can exist in multiple states simultaneously.\\n    * **Entanglement:** This is a bizarre but crucial part.  When two qubits are entangled, they become linked.  If you change the state of one, the other *instantly* changes to reflect that change, no matter how far apart they are.  It\\'s like having two coins that always land on opposite sides â€“ even if they\\'re separated by the universe.\\n\\n**3. Why is this powerful?**\\n\\nBecause of superposition and entanglement, quantum computers can explore many possibilities *simultaneously*. This allows them to tackle problems that are impossible for even the most powerful classical computers to solve in a reasonable amount of time.\\n\\n**Here\\'s an analogy:**\\n\\nImagine you\\'re trying to find a specific grain of sand on a beach.\\n\\n* **Classical Computer:**  It would have to check each grain of sand one by one.\\n* **Quantum Computer:** It could look at *all* the grains of sand at the same time, significantly speeding up the search.\\n\\n**What can quantum computers be good at?**\\n\\n* **Drug Discovery:** Simulating molecules to design new medicines.\\n* **Materials Science:** Creating new materials with specific properties.\\n* **Cryptography:** Breaking current encryption methods (and creating new, quantum-resistant ones).\\n* **Optimization:** Solving complex problems like logistics, finance, and artificial intelligence.\\n\\n**Important Note:** Quantum computers aren\\'t going to replace your laptop anytime soon. They\\'re specialized tools for very specific types of problems.\\n\\n**In short, quantum computing leverages the weirdness of quantum mechanics to perform calculations in a fundamentally different way, offering the potential for breakthroughs in many fields.**\\n\\n---\\n\\n**Resources for Further Learning:**\\n\\n* **Quantum Computing for Dummies:** [https://www.quantumcomputingfordummies.com/](https://www.quantumcomputingfordummies.com/)\\n* **IBM Quantum:** [https://www.ibm.com/quantum](https://www.ibm.com/quantum)\\n* **YouTube - Quantum Computing Explained:** [https://www.youtube.com/watch?v=Q8G7J663X9I](https://www.youtube.com/watch?v=Q8G7J663X9I)\\n\\n\\nDo you want me to delve deeper into a specific aspect, like:\\n\\n*   The math behind qubits?\\n*   A specific application (like drug discovery)?' additional_kwargs={} response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T20:53:51.117858Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20762616834, 'load_duration': 1529433875, 'prompt_eval_count': 14, 'prompt_eval_duration': 357597125, 'eval_count': 759, 'eval_duration': 17794923825, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'} id='lc_run--3c147f6a-bd91-43e5-9070-aaeb37ab2041-0' usage_metadata={'input_tokens': 14, 'output_tokens': 759, 'total_tokens': 773}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0.2)\n",
    "\n",
    "response = llm.invoke(\"Explain quantum computing simply.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1195a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the bear cross the playground? \\n\\nTo get to the other slide! \\n\\n---\\n\\nWould you like to hear another one? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T20:57:43.251337Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3677442500, 'load_duration': 253345583, 'prompt_eval_count': 16, 'prompt_eval_duration': 2663287250, 'eval_count': 31, 'eval_duration': 637025666, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'}, id='lc_run--9609f3ea-f4ce-4f6b-a72e-65cef63422fc-0', usage_metadata={'input_tokens': 16, 'output_tokens': 31, 'total_tokens': 47})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Tell me a joke about bears!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84334f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the bear cross the playground? \\n\\nTo get to the other slide! \\n\\n---\\n\\nWould you like to hear another one? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T21:00:38.948449Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1304569041, 'load_duration': 203248250, 'prompt_eval_count': 16, 'prompt_eval_duration': 369762375, 'eval_count': 31, 'eval_duration': 678683457, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'}, id='lc_run--d57f897b-ca53-4760-a04d-5a4e3e62fe87-0', usage_metadata={'input_tokens': 16, 'output_tokens': 31, 'total_tokens': 47})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(\"Tell me a joke about bears!\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d626f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "joke_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class comedian.\"),\n",
    "    (\"human\", \"Tell me a joke about {topic}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5da4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class comedian.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about beets', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_prompt.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8257748",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = joke_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b3723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Alright, alright, settle down folks! Letâ€™s talk about beets. You know, theyâ€™re like tiny, crimson grenades of flavor. \\n\\n(Pauses for a beat, leans into the microphone)\\n\\nâ€¦Seriously though, why did the beet cross the playground? \\n\\n(Dramatic pause, shrugs)\\n\\nâ€¦To get to the other slide! \\n\\n(Big grin)\\n\\nDonâ€™t tell me youâ€™ve *never* had a beet? \\n\\n---\\n\\n(Adjusts microphone slightly)\\n\\nOkay, okay, Iâ€™ll give you a little more.  Itâ€™s a classic.  \\n\\nWhy did the beet cross the road? \\n\\nâ€¦To prove he wasnâ€™t chicken! \\n\\n(Wipes brow with a hand)\\n\\nAlright, alright!  Youâ€™ve been good.  Want another one?', additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T21:27:50.465026Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7165451250, 'load_duration': 1947793500, 'prompt_eval_count': 27, 'prompt_eval_duration': 754113792, 'eval_count': 176, 'eval_duration': 4111591374, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'}, id='lc_run--cfb3214d-1915-43b3-bd25-3853d4d67e2a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 176, 'total_tokens': 203})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74caf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "str_chain = chain | StrOutputParser()\n",
    "\n",
    "# Equivalent to:\n",
    "# str_chain = joke_prompt | chat_model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c9a2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alright, alright, settle down folks! Letâ€™s talk about beets. You know, theyâ€™re like little crimson jewels, right? \\n\\n(Pauses for a beat, leans into the microphone)\\n\\nâ€¦Seriously though, I was thinking about how beets are surprisingly complex. Theyâ€™re a vegetable, but theyâ€™re also a metaphor forâ€¦ well, letâ€™s just say a really intense, slightly earthy, and surprisingly delicious *transformation*. \\n\\n(Winks)\\n\\nWant another one? \\n\\n---\\n\\n**(Joke ends with a slight flourish and a knowing smile)** \\n\\n---\\n\\nOkay, okay, youâ€™ve heard it.  Now, letâ€™s move on to something a littleâ€¦ less beet-related.  What do you call a beet thatâ€™s a little grumpy? \\n\\n(Pause for a chuckle)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_chain.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88860003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright|,| alright|,| settle| down| folks|!| Let|â€™|s| talk| about| beets|.| You| know|,| they|â€™|re| like| tiny|,| crimson| grenades| of| flavor|.| |\n",
      "\n",
      "|(|Pa|uses| for| a| beat|,| leans| into| the| microphone|)|\n",
      "\n",
      "|â€¦|Seriously| though|,| why| did| the| beet| cross| the| playground|?| |\n",
      "\n",
      "|(|Dramatic| pause|,| shrug|s|)|\n",
      "\n",
      "|â€¦|To| get| to| the| other| slide|!| |\n",
      "\n",
      "|(|Big|,| slightly| exaggerated| laugh|)|\n",
      "\n",
      "|Don|â€™|t| tell| me| you|â€™|ve| ever| tried| to| make| a| beet| salad|?| It|â€™|s| a| *|serious|*| undertaking|.| |\n",
      "\n",
      "|---|\n",
      "\n",
      "|(|Quick|ly|,| with| a| wink|)|\n",
      "\n",
      "|Okay|,| okay|,| I|â€™|ll| stop|.|  |Just|â€¦| let|â€™|s| move| on| to| something| a| little| less|â€¦| root|-|y|.| |\n",
      "\n",
      "|---|\n",
      "\n",
      "|Want| another| one|?|||"
     ]
    }
   ],
   "source": [
    "for chunk in str_chain.stream({\"topic\": \"beets\"}):\n",
    "    print(chunk, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65531b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
