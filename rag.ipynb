{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2536e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Today is November 2, 2023. \\n\\nDo you want me to tell you anything else about the date? For example, do you want to know:\\n\\n*   The weather in a specific location?\\n*   News headlines?' additional_kwargs={} response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T22:08:04.805462Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1897251959, 'load_duration': 198640667, 'prompt_eval_count': 15, 'prompt_eval_duration': 439912041, 'eval_count': 53, 'eval_duration': 1178447377, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'} id='lc_run--b9cd88e5-ff4d-426c-a713-3c504ca2a447-0' usage_metadata={'input_tokens': 15, 'output_tokens': 53, 'total_tokens': 68}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\", temperature=0.2)\n",
    "\n",
    "response = llm.invoke(\"What is the current date?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39af53b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of today, November 24, 2023, the current date is 2023-11-24. \\n\\nIs there anything specific you'd like to know about the date?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that the current date is \"{current_date}\".'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18cdb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"According to various sources, the Old Ship Saloon's total revenue in Q1 2023 was approximately **£68,000**.\\n\\nIt's important to note that this figure is based on reports and estimates from various sources, and the exact number might fluctuate slightly depending on the specific reporting period.\", additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-11-24T22:13:18.123358Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2258290584, 'load_duration': 229497125, 'prompt_eval_count': 29, 'prompt_eval_duration': 397615167, 'eval_count': 68, 'eval_duration': 1514155040, 'logprobs': None, 'model_name': 'gemma3:1b', 'model_provider': 'ollama'}, id='lc_run--301f77fb-ddd7-4ed7-9684-e20bea45a587-0', usage_metadata={'input_tokens': 29, 'output_tokens': 68, 'total_tokens': 97})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What was the Old Ship Saloon's total revenue in Q1 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f86d417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Old Ship Saloon’s total revenue in Q1 2023 was $174782.38.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE = \"\"\"\n",
    "Old Ship Saloon 2023 quarterly revenue numbers:\n",
    "Q1: $174782.38\n",
    "Q2: $467372.38\n",
    "Q3: $474773.38\n",
    "Q4: $389289.23\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You are a helpful assistant. Use the following context when responding:\\n\\n{context}.'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "\n",
    "rag_chain.invoke({\n",
    "    \"question\": \"What was the Old Ship Saloon's total revenue in Q1 2023?\",\n",
    "    \"context\": SOURCE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_KEY\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"YOUR_PROJECT\"\n",
    "\n",
    "chain.invoke({\n",
    "  \"question\": \"What is the current date?\",\n",
    "  \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9436bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"gemma3:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d9e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
